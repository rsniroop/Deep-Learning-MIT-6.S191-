{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPuAll5CIEaoSm6inS61J3T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsniroop/Deep-Learning-MIT-6.S191-/blob/master/Deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zWvsGMWE8dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxcbPViOFAIg",
        "colab_type": "code",
        "outputId": "a289a5bf-3b39-47e4-bf0c-b253e6b55175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download and import the MIT 6.S191 package\n",
        "!pip install mitdeeplearning\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mitdeeplearning in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from mitdeeplearning) (0.15.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from mitdeeplearning) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from mitdeeplearning) (1.18.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from mitdeeplearning) (4.28.1)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from gym->mitdeeplearning) (1.14.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->mitdeeplearning) (1.4.10)\n",
            "Requirement already satisfied: scipy in /tensorflow-2.1.0/python3.6 (from gym->mitdeeplearning) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->mitdeeplearning) (1.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->mitdeeplearning) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJdQBlWFFNlx",
        "colab_type": "code",
        "outputId": "b3c159ff-d657-466f-c666-1e3a786e581c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "sport = tf.constant(\"Tennis\", tf.string)\n",
        "number = tf.constant(1.41421356237, tf.float64)\n",
        "\n",
        "print(\"`sport` is a {}-d Tensor\".format(tf.rank(sport)))\n",
        "print(\"`number` is a {}-d Tensor\".format(tf.rank(number).numpy()))\n",
        "\n",
        "sports = tf.constant([\"Tennis\", \"Basketball\"], tf.string)\n",
        "numbers = tf.constant([3.141592, 1.414213, 2.71821], tf.float64)\n",
        "\n",
        "print(\"`sports` is a {}-d Tensor with shape: {}\".format(tf.rank(sports).numpy(), tf.shape(sports)))\n",
        "print(\"`numbers` is a {}-d Tensor with shape: {}\".format(tf.rank(numbers).numpy(), tf.shape(numbers)))\n",
        "\n",
        "### Defining higher-order Tensors ###\n",
        "\n",
        "'''TODO: Define a 2-d Tensor''' ###DONE!!!!!\n",
        "matrix = tf.constant([[0,1,1],[2,3,5],[4,5,9],[6,7,13]], tf.int16)\n",
        "\n",
        "assert isinstance(matrix, tf.Tensor), \"matrix must be a tf Tensor object\"\n",
        "assert tf.rank(matrix).numpy() == 2\n",
        "\n",
        "\n",
        "'''TODO: Define a 4-d Tensor.'''  ###DONE!!!\n",
        "# Use tf.zeros to initialize a 4-d Tensor of zeros with size 10 x 256 x 256 x 3. \n",
        "#   You can think of this as 10 images where each image is RGB 256 x 256.\n",
        "images = tf.zeros((10, 256, 256,3), dtype = tf.int32)\n",
        "\n",
        "assert isinstance(images, tf.Tensor), \"matrix must be a tf Tensor object\"\n",
        "assert tf.rank(images).numpy() == 4, \"matrix must be of rank 4\"\n",
        "assert tf.shape(images).numpy().tolist() == [10, 256, 256, 3], \"matrix is incorrect shape\"\n",
        "\n",
        "row_vector = matrix[1]\n",
        "column_vector = matrix[:,2]\n",
        "scalar = matrix[1, 2]\n",
        "\n",
        "print(\"`row_vector`: {}\".format(row_vector.numpy()))\n",
        "print(\"`column_vector`: {}\".format(column_vector.numpy()))\n",
        "print(\"`scalar`: {}\".format(scalar.numpy()))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`sport` is a 0-d Tensor\n",
            "`number` is a 0-d Tensor\n",
            "`sports` is a 1-d Tensor with shape: [2]\n",
            "`numbers` is a 1-d Tensor with shape: [3]\n",
            "`row_vector`: [2 3 5]\n",
            "`column_vector`: [ 1  5  9 13]\n",
            "`scalar`: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XajVQp8GH1Uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6b387891-f09e-40cd-b709-f1a106de417c"
      },
      "source": [
        "# Create the nodes in the graph, and initialize values\n",
        "a = tf.constant(15)\n",
        "b = tf.constant(61)\n",
        "\n",
        "# Add them!\n",
        "c1 = tf.add(a,b)\n",
        "c2 = a + b # TensorFlow overrides the \"+\" operation so that it is able to act on Tensors\n",
        "print(c1)\n",
        "print(c2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(76, shape=(), dtype=int32)\n",
            "tf.Tensor(76, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBdLR2uuIFJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdc6da22-c2db-4fc9-a7e8-8e2a0251296e"
      },
      "source": [
        "### Defining Tensor computations ###\n",
        "\n",
        "# Construct a simple computation function\n",
        "def func(a,b):\n",
        "  '''TODO: Define the operation for c, d, e (use tf.add, tf.subtract, tf.multiply).'''\n",
        "  c = a + b\n",
        "  d = b - 1\n",
        "  e = c * d\n",
        "  return e\n",
        "\n",
        "# Consider example values for a,b\n",
        "a, b = 1.5, 2.5\n",
        "# Execute the computation\n",
        "e_out = func(a,b)\n",
        "print(e_out)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvslDJtzJdxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "276e40be-74be-4c34-f08b-9b584f83a93e"
      },
      "source": [
        "### Defining a network Layer ###\n",
        "\n",
        "# n_output_nodes: number of output nodes\n",
        "# input_shape: shape of the input\n",
        "# x: input to the layer\n",
        "\n",
        "class OurDenseLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, n_output_nodes):\n",
        "    super(OurDenseLayer, self).__init__()\n",
        "    self.n_output_nodes = n_output_nodes\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    d = int(input_shape[-1])\n",
        "    # Define and initialize parameters: a weight matrix W and bias b\n",
        "    # Note that parameter initialization is random!\n",
        "    self.W = self.add_weight(\"weight\", shape=[d, self.n_output_nodes]) # note the dimensionality\n",
        "    self.b = self.add_weight(\"bias\", shape=[1, self.n_output_nodes]) # note the dimensionality\n",
        "\n",
        "  def call(self, x):\n",
        "    '''TODO: define the operation for z (hint: use tf.matmul)'''\n",
        "    z = tf.matmul(x, self.W) + self.b\n",
        "\n",
        "    '''TODO: define the operation for out (hint: use tf.sigmoid)'''\n",
        "    y = tf.sigmoid(z)\n",
        "    return y\n",
        "\n",
        "# Since layer parameters are initialized randomly, we will set a random seed for reproducibility\n",
        "tf.random.set_seed(1)\n",
        "layer = OurDenseLayer(3)\n",
        "layer.build((1,2))\n",
        "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
        "y = layer.call(x_input)\n",
        "\n",
        "# test the output!\n",
        "print(y.numpy())\n",
        "mdl.lab1.test_custom_dense_layer_output(y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.2697859  0.45750418 0.66536945]]\n",
            "[PASS] test_custom_dense_layer_output\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhImZyfoU3Kc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f86802a-1e0b-4cb7-b0e8-c77cfdc84c0b"
      },
      "source": [
        "### Defining a neural network using the Sequential API ###\n",
        "\n",
        "# Import relevant packages\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the number of outputs\n",
        "n_output_nodes = 3\n",
        "\n",
        "# First define the model \n",
        "model = Sequential()\n",
        "\n",
        "'''TODO: Define a dense (fully connected) layer to compute z'''\n",
        "# Remember: dense layers are defined by the parameters W and b!\n",
        "# You can read more about the initialization of W and b in the TF documentation :) \n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?version=stable\n",
        "dense_layer = Dense(n_output_nodes, activation='sigmoid')\n",
        "\n",
        "# Add the dense layer to the model\n",
        "model.add(dense_layer)\n",
        "\n",
        "\n",
        "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
        "\n",
        "'''TODO: feed input into the model and predict the output!'''\n",
        "model_output = model(x_input).numpy()\n",
        "print(model_output)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5607363 0.6566898 0.1249697]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0duyaMOUlFzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13812f4c-47c6-42ca-9dbf-35f34c176afb"
      },
      "source": [
        "### Defining a model using subclassing ###\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class SubclassModel(tf.keras.Model):\n",
        "\n",
        "  # In __init__, we define the Model's layers\n",
        "  def __init__(self, n_output_nodes):\n",
        "    super(SubclassModel, self).__init__()\n",
        "    '''TODO: Our model consists of a single Dense layer. Define this layer.''' \n",
        "    self.dense_layer = Dense(n_output_nodes, activation='sigmoid')\n",
        "  # In the call function, we define the Model's forward pass.\n",
        "  def call(self, inputs):\n",
        "    return self.dense_layer(inputs)\n",
        "\n",
        "n_output_nodes = 3\n",
        "model = SubclassModel(n_output_nodes)\n",
        "\n",
        "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
        "\n",
        "print(model.call(x_input))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.6504887  0.47828162 0.8373661 ]], shape=(1, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7NHIRN1lbbW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22b1e891-8ee7-463f-dd47-90bf5393214c"
      },
      "source": [
        "### Defining a model using subclassing and specifying custom behavior ###\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class IdentityModel(tf.keras.Model):\n",
        "\n",
        "  # As before, in __init__ we define the Model's layers\n",
        "  # Since our desired behavior involves the forward pass, this part is unchanged\n",
        "  def __init__(self, n_output_nodes):\n",
        "    super(IdentityModel, self).__init__()\n",
        "    self.dense_layer = tf.keras.layers.Dense(n_output_nodes, activation='sigmoid')\n",
        "\n",
        "  '''TODO: Implement the behavior where the network outputs the input, unchanged, \n",
        "      under control of the isidentity argument.'''\n",
        "  def call(self, inputs, isidentity=False):\n",
        "    x = self.dense_layer(inputs)\n",
        "    '''TODO: Implement identity behavior'''\n",
        "    if isidentity:\n",
        "        return inputs\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "n_output_nodes = 3\n",
        "model = IdentityModel(n_output_nodes)\n",
        "\n",
        "x_input = tf.constant([[1,2.]], shape=(1,2))\n",
        "'''TODO: pass the input into the model and call with and without the input identity option.'''\n",
        "out_activate = model.call(x_input)\n",
        "out_identity = model.call(x_input, True)\n",
        "\n",
        "print(\"Network output with activation: {}; network identity output: {}\".format(out_activate.numpy(), out_identity.numpy()))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network output with activation: [[0.29996255 0.62776643 0.48460072]]; network identity output: [[1. 2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZNx9IN7nptB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d54212d-9500-4756-e2b3-3cd03bde1bf6"
      },
      "source": [
        "### Gradient computation with GradientTape ###\n",
        "\n",
        "# y = x^2\n",
        "# Example: x = 3.0\n",
        "x = tf.Variable(1.0)\n",
        "\n",
        "# Initiate the gradient tape\n",
        "with tf.GradientTape() as tape:\n",
        "  # Define the function\n",
        "  y = tf.math.exp(x)\n",
        "# Access the gradient -- derivative of y with respect to x\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(dy_dx.numpy())\n",
        "#assert dy_dx.numpy() == 27.0"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.7182817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "821A66plo1Gk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "bca36cf6-6fc5-47f8-8fba-7db3f041feb6"
      },
      "source": [
        "### Function minimization with automatic differentiation and SGD ###\n",
        "\n",
        "# Initialize a random value for our initial x\n",
        "x = tf.Variable([tf.random.normal([1])])\n",
        "print(\"Initializing x={}\".format(x.numpy()))\n",
        "\n",
        "learning_rate = 1e-2 # learning rate for SGD\n",
        "history = []\n",
        "# Define the target value\n",
        "x_f = 4\n",
        "\n",
        "# We will run SGD for a number of iterations. At each iteration, we compute the loss, \n",
        "#   compute the derivative of the loss with respect to x, and perform the SGD update.\n",
        "for i in range(500):\n",
        "  with tf.GradientTape() as tape:\n",
        "    '''TODO: define the loss as described above'''\n",
        "    loss = (x - x_f) ** 2\n",
        "\n",
        "  # loss minimization using gradient tape\n",
        "  grad = tape.gradient(loss, x) # compute the derivative of the loss with respect to x\n",
        "  new_x = x - learning_rate*grad # sgd update\n",
        "  x.assign(new_x) # update the value of x\n",
        "  history.append(x.numpy()[0])\n",
        "\n",
        "# Plot the evolution of x as we optimize towards x_f!\n",
        "plt.plot(history)\n",
        "plt.plot([0, 500],[x_f,x_f])\n",
        "plt.legend(('Predicted', 'True'))\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('x value')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing x=[[-0.39749852]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'x value')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npP4/HY5VLJWiLkMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}